# -*- coding: utf-8 -*-
"""ClassifyImages.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ADx4iqJyLmJhIwFY6uRpynJg7trbQop7
"""

from keras.datasets import cifar10
(x_train,y_train), (x_test, y_test) = cifar10.load_data()

print(type(x_train))
print(type(y_train))
print(type(x_test))
print(type(y_test))

#getting the shape of our data, 
print('x_train shape:', x_train.shape)
print('y_train shape:', y_train.shape)
print('x_test shape:', x_test.shape)
print('y_test shape:', y_test.shape)

#looking at the first image in our dataset, located at index 0 in our training dataset

x_train[0]

#let's look at the image as a picture now

import matplotlib.pyplot as plt
img=plt.imshow(x_train[0])

#printing the label of the image

print('Label is:', y_train[0])

#one hot encoding (we will convert the labels into a set of 10 numbers and later on use this as an input to our neural network.)

from keras.utils import to_categorical
y_train_one_hot = to_categorical(y_train)
y_test_one_hot = to_categorical(y_test)

print(y_train_one_hot)

#printing the new labels
print('The one-hot label is: ', y_train_one_hot[0])

#we will normalize the pixels in the images to values between 0 and 1

x_train= x_train/255 #normally the image size is 255 so to get 0 and 1 we divide it by 255
x_test= x_test/255

#Using our keras library now we will build our CNN

from keras.models import Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D
model=Sequential() #creates the architecture

#create cnn layer, used to extract features from input image containing convolve features and relu

model.add(Conv2D(32,(5,5),activation='relu',input_shape=(32,32,3))) #32,32 pixels with depth of 3, we used relu activation function
model.add(MaxPooling2D(pool_size=(2,2))) #2x2 filter used for max pooling 

model.add(Conv2D(32,(5,5),activation='relu'))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Flatten()) #we flatten our image and make it a linear array or 1d vector to connect it to our neural network
model.add(Dense(1000,activation='relu')) #dense layers with RelU activation function
model.add(Dense(10,activation='softmax')) #10 neurons chosen as number of labels we have is 10.

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy']) #we used this loss function because we have 10 different classes that is greater than 2.



# now we will train our model

hist = model.fit(x_train, y_train_one_hot, batch_size=256, epochs=10, validation_split=0.3) #70% data will be used for training and 30% for validation

model.evaluate(x_test, y_test_one_hot)[1]

plt.plot(hist.history['acc'])
plt.plot(hist.history['val_acc'])
plt.title('Accuracy of Model')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train','Val'],loc='lower right')

plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Loss of Model')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train','Val'],loc='lower right')

from google.colab import files
uploaded=files.upload()
my_image=plt.imread('s.jpg')

#showing the uploaded img

img= plt.imshow(my_image)

from skimage.transform import resize
my_image_resized=resize(my_image,(32,32,3))
img=plt.imshow(my_image_resized)

#probabilities for each class (we will get an array of prob)

import numpy as np
probabilities = model.predict(np.array([my_image_resized,]))

#printing probabilities

probabilities

number_to_class=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']
index = np.argsort(probabilities[0,:])

print('Most likely class:',number_to_class[index[9]],'--probability:',probabilities[0,index[9]])
print('Second Most likely class:',number_to_class[index[8]],'--probability:',probabilities[0,index[8]])
print('Third Most likely class:',number_to_class[index[7]],'--probability:',probabilities[0,index[7]])
print('Fourth Most likely class:',number_to_class[index[6]],'--probability:',probabilities[0,index[6]])
print('Fifth Most likely class:',number_to_class[index[5]],'--probability:',probabilities[0,index[5]])

model.save('my_model.h5')

from keras.models import load_model
model=load_model('my_model.h5')

